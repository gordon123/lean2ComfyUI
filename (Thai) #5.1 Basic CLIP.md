# Stable diffusion ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£

![stable diffusion](image-4.png)
**Picture 1.** Simple steps to generate image with stable diffusion <br>

 ‡∏ñ‡πâ‡∏≤‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏ö‡πâ‡∏≤‡∏ô ‡πÜ ‡∏î‡∏π‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡πÄ‡∏•‡∏¢ ‡∏Ñ‡∏∑‡∏≠ ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏Ç‡∏≠‡∏á Stable diffusion  ‡∏´‡∏•‡∏±‡∏Å ‡πÜ ‡∏™‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ ‡∏Ñ‡∏∑‡∏≠ CLIP, U-NET ‡πÅ‡∏•‡∏∞ VAE
 ‡∏à‡∏ö ‡∏Å‡∏≤‡∏£‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡πÜ ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏Ñ‡πà‡∏ô‡∏µ‡πâ ‡πÄ‡∏à‡∏ô‡∏£‡∏π‡∏õ‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß

---
 ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÉ‡∏Ñ‡∏£‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô (‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ) ‡∏•‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡πà‡∏≠

‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å Stable diffusion ‡∏°‡∏µ‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å ‡πÜ  3 ‡πÇ‡∏°‡πÄ‡∏î‡∏• 

1. CLIP - ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà ‡∏†‡∏≤‡∏û‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ ‡∏Å‡∏≤‡∏£ Transformer (‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡πÉ‡∏ô‡∏£‡∏π‡∏õ Vecter, matric, Tensors, Flat number) ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Vision Transformer (ViT) ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤  Text transformer
![example vector to tensor](image-8.png) <br>
**Picture 2.** Example vector to Tensors <br>

![image](https://github.com/user-attachments/assets/c7ed0400-06a6-4d71-ad75-a7d00a50d3b0) <br>
**Picture 3.** ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡πÅ‡∏•‡∏∞ Tensor ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç <br>

3. U-NET - ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£ denoise ‡∏£‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠ 5.2
4. VAE - ‡∏ï‡∏±‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏ó‡πà ‡πÜ ‡∏ß‡πà‡∏≤ Encode ‡∏à‡∏≤‡∏Å Pixel (‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û 512 x 512 x 3 RGB color ) ‡πÄ‡∏õ‡πá‡∏ô Latent (64 x 64 x 4 channels) ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™ ‡πÅ‡∏õ‡∏•‡∏á Latent ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô Pixel ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û - ‡∏£‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠ 5.3


## 5.1 ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á CLIP
‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á CLIP ‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° "‡πÅ‡∏°‡∏ß" <br><br>
**CLIP (Contrastive Language-Image Pretraining)** ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ OpenAI ‡∏ã‡∏∂‡πà‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Text) ‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û (Image) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Contrastive Learning ‡πÄ‡∏°‡∏∑‡πà‡∏≠ CLIP ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô "‡πÅ‡∏°‡∏ß", ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡πá‡∏ô 4 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏Å: ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ<br>

1Ô∏è‚É£ Tokenization (‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à)

üîπ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å, ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° "‡πÅ‡∏°‡∏ß" ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á Text Encoder <br>
üîπ CLIP ‡πÉ‡∏ä‡πâ Byte-Pair Encoding (BPE) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡πÄ‡∏õ‡πá‡∏ô Token IDs ‡πÄ‡∏ä‡πà‡∏ô [[1, 1, 1, 1]]<br>

2Ô∏è‚É£ Text Encoding (‡πÅ‡∏õ‡∏•‡∏á Token ‡πÄ‡∏õ‡πá‡∏ô Vector ‡∏ù‡∏±‡∏á‡∏ï‡∏±‡∏ß - Embedding) <br>
‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Tokenization, CLIP ‡∏à‡∏∞‡πÉ‡∏ä‡πâ Transformer-based Text Encoder ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå (Text Embedding)

üí° ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô Text Encoder

‡πÉ‡∏ä‡πâ Pre-trained Transformer Model ‡πÄ‡∏ä‡πà‡∏ô ViT ‡∏´‡∏£‡∏∑‡∏≠ ResNet
‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° "‡πÅ‡∏°‡∏ß" ‡πÄ‡∏õ‡πá‡∏ô Vector Embedding ‡∏Ç‡∏ô‡∏≤‡∏î 512 ‡∏´‡∏£‡∏∑‡∏≠ 768 ‡∏°‡∏¥‡∏ï‡∏¥
Self-Attention Mechanism ‡∏ä‡πà‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
 ### ‡πÄ‡∏ä‡πà‡∏ô Output: torch.Size([1, 4, 768])

| ‡πÇ‡∏°‡πÄ‡∏î‡∏•        | ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏±‡∏Å                       | ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Stable Diffusion ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?  | Hugging Face Model | Research Paper |
|-------------|--------------------------------|--------------------------------|--------------------|----------------|
| **CLIP**    | Text-to-Image Matching        | ‡πÅ‡∏õ‡∏•‡∏á Prompt ‡πÄ‡∏õ‡πá‡∏ô Text Embedding | [openai/clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14) | [CLIP: Contrastive Language-Image Pretraining](https://arxiv.org/abs/2103.00020) |
| **T5**      | Text-to-Text Learning         | ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Prompt Engineering | [t5-base](https://huggingface.co/t5-base) | [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) |
| **BART**    | Denoising & Summarization     | ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Prompt ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ | [facebook/bart-large](https://huggingface.co/facebook/bart-large) | [BART: Denoising Sequence-to-Sequence Pre-training](https://arxiv.org/abs/1910.13461) |
| **ViT**     | Image Understanding           | ‡πÉ‡∏ä‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å SD | [google/vit-base-patch16-224](https://huggingface.co/google/vit-base-patch16-224) | [An Image is Worth 16x16 Words: Transformers for Image Recognition](https://arxiv.org/abs/2010.11929) |
| **LDM**     | Latent Diffusion Model        | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á Stable Diffusion | [CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4) | [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752) |

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏Ç‡∏≠‡∏á ‡πÇ‡∏°‡∏•‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö CLIP etc. <br>

3Ô∏è‚É£ ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Image Embeddings (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö) <br>
‡∏´‡∏≤‡∏Å CLIP ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° "‡πÅ‡∏°‡∏ß", ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ: <br>

üîπ Image Encoding (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå) <br>

CLIP ‡πÉ‡∏ä‡πâ Vision Transformer (ViT) ‡∏´‡∏£‡∏∑‡∏≠ ResNet <br>
‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô Image Embedding ‡∏Ç‡∏ô‡∏≤‡∏î 768 ‡∏°‡∏¥‡∏ï‡∏¥ <br>
üîπ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ô ***(Cosine Similarity)***

‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Cosine Similarity ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Text Embedding ‡πÅ‡∏•‡∏∞ Image Embedding <br>
‡∏´‡∏≤‡∏Å ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô <br>

4Ô∏è‚É£ Output & Decision (‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå) <br>
üîπ ‡∏´‡∏≤‡∏Å Cosine Similarity ‡∏™‡∏π‡∏á, ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≤‡∏à ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° "‡πÅ‡∏°‡∏ß"<br>
üîπ ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö, CLIP ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ embedding ‡πÄ‡∏û‡∏∑‡πà‡∏≠:<br>

‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• <br>
‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏∞‡πÑ‡∏£ <br>

# üñºÔ∏è Step-by-Step ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Embedding Calculation <br>

## **1Ô∏è‚É£ ‡πÅ‡∏õ‡∏•‡∏á ‡∏£‡∏π‡∏õ ‡∏´‡∏£‡∏∑‡∏≠ Text ‡πÄ‡∏õ‡πá‡∏ô vector (4D)**
| **Input**   | **Vector Representation** |
|------------|--------------------------|
| üê± **‡∏£‡∏π‡∏õ Cat**  | `[0.2, 0.7, 0.1, 0.9]` |
| **"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° cat"**  | `[0.2, 0.7, 0.1, 0.9]` |
| **"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° dog"**  | `[0.3, 0.6, 0.2, 0.8]` |
| **"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° car"**  | `[0.9, 0.1, 0.4, 0.2]` |

---

## 2Ô∏è‚É£ ‡∏™‡∏π‡∏ï‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Cosine similarity

![alt text](image-5.png) <br>
**Picture 4.** ‡∏™‡∏°‡∏≤‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Cosine Similarity ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏Å‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô <br>

where:
- ** A = Image Embedding**
- ** B = Text Embedding**
- ** A.B** = Dot Product
- ** ||A||,||B||** = Magnitudes (Vector Norms)

---

## **3Ô∏è‚É£ Compute Dot Product**

### **üîπ Dot Product ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏°‡∏ß üê± ‡πÅ‡∏•‡∏∞ "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° cat"**
\[(0.2 x 0.2) + (0.7 x 0.7) + (0.1 x 0.1) + (0.9 x 0.9)\]\[= 0.04 + 0.49 + 0.01 + 0.81 = 1.35\]

### **üîπ Dot Product ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏°‡∏ß üê± ‡πÅ‡∏•‡∏∞ "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° dog"**
\[(0.2 x 0.3) + (0.7 x 0.6) + (0.1 x 0.2) + (0.9 x 0.8)\]\[= 0.06 + 0.42 + 0.02 + 0.72 = 1.22\]

### **üîπ Dot Product ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏°‡∏ß üê± ‡πÅ‡∏•‡∏∞ "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° car"**
\[(0.2 x 0.9) + (0.7 x 0.1) + (0.1 x 0.4) + (0.9 x 0.2)\]\[= 0.18 + 0.07 + 0.04 + 0.18 = 0.47\]

‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏°‡∏ß ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ ‡πÅ‡∏°‡∏ß ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ 1.35 / ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏°‡∏ß ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ ‡∏´‡∏°‡∏≤ ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ 1.22 / ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏°‡∏ß ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ ‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ 0.47 
‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏â‡∏ô‡∏±‡πâ‡∏ô ‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤‡πÅ‡∏°‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏≤‡∏°‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡πÅ‡∏°‡∏ß‡πÑ‡∏î‡πâ ‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ
---

## **4Ô∏è‚É£ Compute Magnitudes (Vector Norms)**
Magnitude (Norm) ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡∏≠‡∏Å ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÉ‡∏ô‡∏°‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏°‡∏±‡∏ô ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Cosine Similarity, Distance Calculation ‡πÅ‡∏•‡∏∞ Normalization <br>
üîπ ‡πÉ‡∏ô Image & Text Embedding, ‡πÄ‡∏£‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Norm ‡πÄ‡∏û‡∏∑‡πà‡∏≠: <br>

‡∏ß‡∏±‡∏î‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≠‡∏á‡∏ï‡∏±‡∏ß <br>
‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Cosine Similarity ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á <br>
‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (Normalization) <br>
### **üîπ Magnitude ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏°‡∏ß üê±** <br>
‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏£‡∏≤‡∏°‡∏µ vector ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û <br>
A=[0.2,0.7,0.1,0.9] <br>

![magnitude of image calculation](image-6.png)
**Picture 5.** ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì magnitude ‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û <br>
‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Cosine Similarity, ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Magnitude ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå: <br>
‡πÉ‡∏ä‡πâ ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå ||A|| <br>
--- 

## **5Ô∏è‚É£ Compute Cosine Similarity** <br>

### **üîπ Cosine Similarity with "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° cat"** <br>

![alt text](image-7.png)

---

## **üìä 6Ô∏è‚É£ Final Ranking Based on Cosine Similarity** <br>

| **Text Option** | **Cosine Similarity** | **Ranking** |
|---------------|------------------|-------------|
| **"A cat"** | **1.00** | ‚úÖ **Best Match** |
| **"A dog"** | **0.99** | üîπ **Second Best** |
| **"A car"** | **0.40** | ‚ùå **Least Similar** |

üéØ ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ **"A cat"** ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ similarity score ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (**1.00**), ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤‡πÅ‡∏°‡∏ß‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ Cosine ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏°‡∏ß‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î üê± <br>

---

### **üìå Summary** <br>
‚úÖ Cosine Similarity ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û  <br>
‚úÖ ‡∏Ñ‡πà‡∏≤‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á ‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô <br>
‚úÖ ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô CLIP, Vision-Language Models  <br>

üîπ ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á CLIP ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö "‡∏â‡∏±‡∏ô‡∏£‡∏±‡∏Å‡πÄ‡∏ò‡∏≠" <br>
1Ô∏è‚É£ Tokenization ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô Token IDs <br>
2Ô∏è‚É£ Text Encoding ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á Text Embedding ‡∏î‡πâ‡∏ß‡∏¢ Transformer <br>
3Ô∏è‚É£ Image Matching (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏†‡∏≤‡∏û) ‚Üí ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Text vs. Image Embedding <br>
4Ô∏è‚É£ Similarity Computation ‚Üí ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Cosine Similarity ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û <br>

‚úÖ ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ‚Üí ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á <br>
‚úÖ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û ‚Üí ‡πÉ‡∏ä‡πâ embedding ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏£‡∏¥‡∏ö‡∏ó <br>


# Step-by-Step Process of a Vision Transformer (ViT) üñºÔ∏è  <br>
‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏™‡πà‡∏†‡∏≤‡∏û‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ ViT ‡∏à‡∏∞‡∏ó‡∏≥‡∏î‡∏±‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ: <br>

1Ô∏è‚É£ ‡πÅ‡∏ö‡πà‡∏á‡∏£‡∏π‡∏õ‡πÉ‡∏´‡∏ç‡πà ‡πÜ ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏¢‡πà‡∏≠‡∏¢ ‡πÜ (‡πÄ‡∏ä‡πà‡∏ô, 16x16 pixels). <br>
‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏¢‡πà‡∏≠‡∏¢ ‡πÜ ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç flat vector <br>

üîπ Example: <br>
‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏π‡∏õ‡∏Ç‡∏ô‡∏≤‡∏î 256√ó256 pixels ‡∏ñ‡∏π‡∏Å‡πÅ‡∏ö‡πà‡∏á‡∏¢‡πà‡∏≠‡∏¢ ‡πÜ ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î 16√ó16 patches, ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å 256 / 16 = 16 patches. <br>

2Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á Patch Embeddings <br>
‡∏£‡∏π‡∏õ‡∏¢‡πà‡∏≠‡∏¢ ‡πÜ ‡∏à‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç <br>
This embedding represents key features of the patch. <br>
üîπ Formula for Patch Embeddings: <br>

![formular patch embedding](image-1.png)

3Ô∏è‚É£ ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤ Token <br>
A [CLS] token ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á <br>

4Ô∏è‚É£ ‡πÉ‡∏ä‡πâ [Transformer Encoder Self-Attention Mechanism](https://arxiv.org/abs/1706.03762) ‡∏Å‡∏î‡∏ó‡∏µ‡πà‡∏•‡∏¥‡πâ‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢ <br>
‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ patch embeddings using multi-head self-attention (MHSA). ‡πÅ‡∏ï‡πà‡∏•‡∏∞ patch ‡∏à‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏° ‡∏Å‡∏±‡∏ö patch ‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå <br>
Self-Attention Mechanism ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Transformer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô Input Sequence ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Query (Q), Key (K), ‡πÅ‡∏•‡∏∞ Value (V) <br>

üìå ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Self-Attention <br>
Query (Q) ‚Üí ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç <br>
Key (K) ‚Üí ‡∏ï‡∏±‡∏ß‡∏ö‡πà‡∏á‡∏ä‡∏µ‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• <br>
Value (V) ‚Üí ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ <br>
![self-attention mechanism](image-2.png) <br>
‡∏ï‡∏≤‡∏°‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å https://arxiv.org/abs/1706.03762 <br>

‡∏ñ‡πâ‡∏≤‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏ö‡πâ‡∏≤‡∏ô ‡πÜ ‡∏Ñ‡∏∑‡∏≠ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà ‡πÜ ‡πÉ‡∏´‡πâ‡πÄ‡∏à‡∏≠‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£  <br>

‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÇ‡∏õ‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏û‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á  <br>
‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏ï‡πà‡∏≠ ‡∏Ç‡πâ‡∏≠ 5.2 ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á U-Net


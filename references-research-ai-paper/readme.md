### ‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å ‡πÜ ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏î‡πâ‡∏≤‡∏ô AI ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à

### References for Text to image generative AI
Image generative Areana! https://huggingface.co/spaces/ArtificialAnalysis/Text-to-Image-Leaderboard

| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏¢‡πà‡∏≠‡πÜ |  Link |
| -------- | ------- | ------- |
| High-Resolution Image Synthesis with Latent Diffusion Models  |  ‡∏ï‡πâ‡∏ô‡∏Å‡∏≥‡πÄ‡∏ô‡∏¥‡∏î Stable diffusion    |https://arxiv.org/abs/2112.10752|
| Reproducible scaling laws for contrastive language-image learning | ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö CLIP ‡∏Ç‡∏≠‡∏á OpenAI     |https://arxiv.org/abs/2212.07143 <br> ‡∏•‡∏¥‡πâ‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° https://github.com/mlfoundations/open_clip|
| TBA    | TBA    |TBA|

### References for Sound/Voice/Musics generative AI 
Sound/Voice clone areana ! https://huggingface.co/spaces/TTS-AGI/TTS-Arena

| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏¢‡πà‡∏≠‡πÜ |  Link |
| -------- | ------- | ------- |
| PyThaiNLP: Thai Natural Language Processing in Python   | TBA    |https://arxiv.org/pdf/2312.04649|
| PyThaiNLP open source   | TBA    |https://pythainlp.org/thai-tutorials/index.html|
| StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion  | TBA    |https://arxiv.org/abs/2306.07691|

### Reference for Video generative AI
The areana!!  https://huggingface.co/spaces/ArtificialAnalysis/Text-to-Image-Leaderboard

| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠    | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏¢‡πà‡∏≠‡πÜ |  Link |
| -------- | ------- | ------- |
| TBA    | TBA    |TBA|


## üîó Summary: Research Papers on Image-to-Text Models

| **Model** | **Paper Title** | **Link** | **Explanation (Thai)** |
|-----------|----------------|----------|----------------------|
| **CLIP** | [Multimodal Foundation Models](https://www.nowpublishers.com/article/Details/CGV-110) | [Now Publishers](https://www.nowpublishers.com/article/Details/CGV-110) | ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏†‡∏≤‡∏û‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û |
| **BLIP** | [Benchmark Evaluations of Large Vision-Language Models](https://arxiv.org/abs/2501.02189) | [arXiv 2501.02189](https://arxiv.org/abs/2501.02189) | ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏û (Image Captioning) ‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û |
| **GPT-4 Vision** | [Unified Approaches for Vision-Language](https://search.proquest.com/openview/9b0e3d8d3074e04922702f883cc9f7c0/1) | [ProQuest](https://search.proquest.com/openview/9b0e3d8d3074e04922702f883cc9f7c0/1) | ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏£‡∏£‡∏Å‡∏∞‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏†‡∏≤‡∏û |
| **SimVLM** | [Simple Visual Language Model](https://arxiv.org/abs/2111.09883) | [arXiv 2111.09883](https://arxiv.org/abs/2111.09883) | ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô‡πÅ‡∏ö‡∏ö‡∏≠‡πà‡∏≠‡∏ô (weakly supervised) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û |
| **LLaVA** | [Multimodal Large Language Models](https://aclanthology.org/2024.ccl-2.1/) | [ACL Anthology](https://aclanthology.org/2024.ccl-2.1/) | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏û ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ LLM |
| **Flamingo** | [Few-Shot Learning for Vision-Language](https://arxiv.org/abs/2204.14198) | [DeepMind](https://arxiv.org/abs/2204.14198) | ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏ö‡∏ö few-shot ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô |
| **Kosmos-2** | [Grounded Multimodal Generation](https://arxiv.org/abs/2306.14824) | [Microsoft](https://arxiv.org/abs/2306.14824) | ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û |
| **GIT** | [Generative Image-to-Text Transformer](https://arxiv.org/abs/2205.14100) | [arXiv 2205.14100](https://arxiv.org/abs/2205.14100) | ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á |
| **Show and Tell** | [A Neural Image Caption Generator](https://arxiv.org/abs/1411.4555) | [arXiv 1411.4555](https://arxiv.org/abs/1411.4555) | ‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ CNN+LSTM ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ |
| **OCR (Tesseract, TrOCR)** | [OCR for Vision-Language Tasks](https://arxiv.org/abs/2401.02276) | [arXiv 2401.02276](https://arxiv.org/abs/2401.02276) | ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û (OCR) ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå ‡πÅ‡∏•‡∏∞‡∏õ‡πâ‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô |

